# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eAyhkXsN-QuHYi6jHhXGgQtfc-VVReij
"""

# =============================================================================
# SAR-RARP50 Model Visualization and Analysis Script
# =============================================================================

#change the path!!!!

import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
import json
import cv2
from torch.utils.data import DataLoader
import torchvision.transforms.functional as TF
import segmentation_models_pytorch as smp

# Add the  directory to the path
import sys
sys.path.append('/content/MMR')

from data.dataloaders.SegNetDataLoaderV2 import SegNetDataset


# =============================================================================
# 1. LOAD TRAINED MODEL AND DATA
# =============================================================================

def load_model_and_data():
    """Load the trained model and prepare data for visualization"""

    # Model parameters
    num_classes = 10
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Load the trained model
    model = smp.UnetPlusPlus(
        encoder_name="resnet18",
        encoder_weights="imagenet",
        in_channels=3,
        classes=num_classes
    )

    # Load the trained weights
    checkpoint_path = "/content/MMR/results/smp_UNet++/sarrarp50/bs_train128_val32/lr1e-3_wd0.00001_dice0.5/e71/smp_UNet++_sarrarp50_bs128lr0.001e71_checkpoint"

    if os.path.exists(checkpoint_path):
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['state_dict'])
        print("Model loaded successfully!")
    else:
        print("No trained model found, using randomly initialized model for demonstration")

    model.to(device)
    model.eval()

    # Load dataset
    data_dir = "/content/MMR/Model/data/datasets/sarrarp50"
    json_path = "/content/MMR/Model/data/classes/sarrarp50SegClasses.json"

    # Load test dataset
    test_dataset = SegNetDataset(
        os.path.join(data_dir, 'test'),
        crop_size=-1,
        json_path=json_path,
        sample='test',
        dataset='sarrarp50',
        image_size=[256, 256]
    )

    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

    # Load class information
    with open(json_path, 'r') as f:
        classes_info = json.load(f)

    return model, test_loader, classes_info, device



# =============================================================================
# 2. VISUALIZATION FUNCTIONS
# =============================================================================



def create_color_map(classes_info):
    """Create color map for visualization"""
    colors = []
    class_names = []

    for class_info in classes_info['classes']:
        color_str = class_info['color']
        # Parse color string like "[255, 0, 0]"
        color = eval(color_str)
        colors.append([c/255.0 for c in color])  # Normalize to 0-1
        class_names.append(class_info['name'])

    return np.array(colors), class_names

def apply_color_map(mask, colors):
    """Apply color map to segmentation mask"""
    h, w = mask.shape
    colored_mask = np.zeros((h, w, 3))

    for class_id in range(len(colors)):
        class_pixels = (mask == class_id)
        colored_mask[class_pixels] = colors[class_id]

    return colored_mask

def visualize_predictions(model, test_loader, classes_info, device, num_samples=4):
    """Visualize using the 'hot' colormap approach"""

    # Dataset mean and std
    mean = torch.tensor([0.485, 0.456, 0.406])
    std = torch.tensor([0.229, 0.224, 0.225])

    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples*4))
    if num_samples == 1:
        axes = axes.reshape(1, -1)

    with torch.no_grad():
        for idx, (image, gt_colored, gt_mask) in enumerate(test_loader):
            if idx >= num_samples:
                break

            # Move to device
            image = image.to(device)

            # Normalize image for model input
            image_norm = torch.zeros_like(image)
            for i in range(3):
                image_norm[:, i, :, :] = (image[:, i, :, :] - mean[i]) / std[i]

            # Get prediction
            pred = model(image_norm)
            pred_mask = torch.argmax(pred, dim=1).cpu().numpy()[0]

            # Convert tensors to numpy for visualization
            image_np = image[0].cpu().permute(1, 2, 0).numpy()
            gt_mask_np = gt_mask[0].numpy()

            # Normalize image for display
            image_np = (image_np - image_np.min()) / (image_np.max() - image_np.min())

            # Plot using 'hot' colormap
            axes[idx, 0].imshow(image_np)
            axes[idx, 0].set_title(f'Original Image {idx+1}')
            axes[idx, 0].axis('off')

            axes[idx, 1].imshow(gt_mask_np, cmap='hot', vmin=0, vmax=9)
            axes[idx, 1].set_title(f'Ground Truth Mask {idx+1}')
            axes[idx, 1].axis('off')

            axes[idx, 2].imshow(pred_mask, cmap='hot', vmin=0, vmax=9)
            axes[idx, 2].set_title(f'Predicted Mask {idx+1}')
            axes[idx, 2].axis('off')

    plt.tight_layout()
    plt.savefig('/content/MMR/prediction_visualization.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Use your original legend function
    create_legend(classes_info)

def create_legend(classes_info):
    """Create legend with actual 'hot' colormap colors"""
    import matplotlib.cm as cm

    class_names = [class_info['name'] for class_info in classes_info['classes']]

    # Get the actual colors from the 'hot' colormap
    hot_colormap = cm.get_cmap('hot')
    colors = []

    for i in range(len(class_names)):
        # Get the color from hot colormap (normalized to 0-1 range)
        color = hot_colormap(i / 9.0)  # 9 is max class index
        colors.append(color[:3])  # Take only RGB, ignore alpha

    fig, ax = plt.subplots(figsize=(10, 6))

    # Create color patches with hot colormap colors
    for i, (color, name) in enumerate(zip(colors, class_names)):
        ax.add_patch(plt.Rectangle((0, i), 1, 0.8, facecolor=color, edgecolor='black'))
        ax.text(1.1, i+0.4, f"{i}: {name}", va='center', fontsize=10)

    ax.set_xlim(0, 4)
    ax.set_ylim(0, len(colors))
    ax.set_aspect('equal')
    ax.axis('off')
    ax.set_title('SAR-RARP50 Class Color Map (Hot Colormap)', fontsize=14, fontweight='bold')

    plt.tight_layout()
    plt.savefig('/content/MMR/class_legend_hot_correct.png', dpi=300, bbox_inches='tight')
    plt.show()

# Update your main function to include the separate legend
def main():
    """Main function to run all visualizations"""
    print("Starting SAR-RARP50 Model Analysis and Visualization...")
    print("="*60)

    # Load model and data
    print("\n1. Loading model and data...")
    model, test_loader, classes_info, device = load_model_and_data()

    # Visualize predictions
    print("\n2. Creating prediction visualizations...")
    visualize_predictions(model, test_loader, classes_info, device, num_samples=4)

    # Create separate legend
    print("\n3. Creating class legend...")
    create_separate_legend(classes_info)

    # Rest of your visualization code...


# =============================================================================
# 4. MODEL ARCHITECTURE VISUALIZATION
# =============================================================================

def visualize_model_architecture(model):
    """Visualize model architecture summary"""

    # Get model summary
    from torchsummary import summary

    print("Model Architecture Summary:")
    print("="*50)

    try:
        # Try to print summary
        summary(model, input_size=(3, 256, 256))
    except:
        print("Model: UNet++ with ResNet18 Encoder")
        print(f"Input Shape: (3, 256, 256)")
        print(f"Output Shape: (10, 256, 256)")
        print(f"Parameters: {sum(p.numel() for p in model.parameters()):,}")
        print(f"Trainable Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

    # Create architecture diagram
    create_architecture_diagram()

def create_architecture_diagram():
    """Create a simple architecture diagram"""

    fig, ax = plt.subplots(figsize=(12, 8))

    # Define components
    components = [
        {'name': 'Input Image\n(3, 256, 256)', 'pos': (1, 7), 'color': '#FFE5B4'},
        {'name': 'ResNet18\nEncoder', 'pos': (3, 7), 'color': '#87CEEB'},
        {'name': 'UNet++\nDecoder', 'pos': (5, 7), 'color': '#98FB98'},
        {'name': 'Output\n(10, 256, 256)', 'pos': (7, 7), 'color': '#FFB6C1'},
        {'name': 'Skip Connections', 'pos': (4, 5), 'color': '#DDA0DD'},
        {'name': 'Nested Dense\nSkip Pathways', 'pos': (4, 3), 'color': '#F0E68C'}
    ]

    # Draw components
    for comp in components:
        rect = plt.Rectangle((comp['pos'][0]-0.4, comp['pos'][1]-0.3), 0.8, 0.6,
                           facecolor=comp['color'], edgecolor='black', linewidth=2)
        ax.add_patch(rect)
        ax.text(comp['pos'][0], comp['pos'][1], comp['name'],
               ha='center', va='center', fontsize=10, fontweight='bold')

    # Draw arrows
    arrows = [
        ((1.4, 7), (2.6, 7)),  # Input to Encoder
        ((3.4, 7), (4.6, 7)),  # Encoder to Decoder
        ((5.4, 7), (6.6, 7)),  # Decoder to Output
        ((3, 6.7), (5, 6.7)),  # Skip connection
    ]

    for start, end in arrows:
        ax.annotate('', xy=end, xytext=start,
                   arrowprops=dict(arrowstyle='->', lw=2, color='red'))

    ax.set_xlim(0, 8)
    ax.set_ylim(2, 8)
    ax.set_aspect('equal')
    ax.axis('off')
    ax.set_title('UNet++ Architecture for SAR-RARP50 Segmentation',
                fontsize=16, fontweight='bold')

    # Add description
    description = ("UNet++ with ResNet18 encoder for surgical instrument segmentation\n"
                  "Features: Nested skip pathways, deep supervision, multi-scale feature fusion")
    ax.text(4, 1.5, description, ha='center', va='center', fontsize=12,
           bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray"))

    plt.tight_layout()
    plt.savefig('/content/MMR/model_architecture.png', dpi=300, bbox_inches='tight')
    plt.show()

def plot_training_metrics():
    """Plot training metrics from log files"""
    # Look for training curves saved during training
    results_dir = "/content/MMR/results/smp_UNet++/sarrarp50/bs_train128_val32/lr1e-3_wd0.00001_dice0.5/e71"

    # Check if training curves exist
    loss_curve_path = os.path.join(results_dir, "loss_smp_UNet++_sarrarp50_bs8lr0.001e50.png")
    acc_curve_path = os.path.join(results_dir, "acc_smp_UNet++_sarrarp50_bs8lr0.001e50.png")

    if os.path.exists(loss_curve_path) and os.path.exists(acc_curve_path):
        print("Training curves found! Displaying saved plots...")

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

        # Load and display loss curve
        loss_img = Image.open(loss_curve_path)
        ax1.imshow(loss_img)
        ax1.set_title('Training Loss Curves')
        ax1.axis('off')

        # Load and display accuracy curve
        acc_img = Image.open(acc_curve_path)
        ax2.imshow(acc_img)
        ax2.set_title('Training Accuracy Curves')
        ax2.axis('off')

        plt.tight_layout()
        plt.savefig('/content/MMR/training_metrics_combined.png', dpi=300, bbox_inches='tight')
        plt.show()
    else:
        print("Training curves not found. Skipping metrics visualization...")

# =============================================================================
# 5. MAIN EXECUTION
# =============================================================================

def main():
    """Main function to run all visualizations"""

    print("Starting SAR-RARP50 Model Analysis and Visualization...")
    print("="*60)

    # Load model and data
    print("\n1. Loading model and data...")
    model, test_loader, classes_info, device = load_model_and_data()

    # Visualize predictions
    print("\n2. Creating prediction visualizations...")
    visualize_predictions(model, test_loader, classes_info, device, num_samples=4)

    # Plot training metrics
    print("\n3. Analyzing training metrics...")
    plot_training_metrics()

    # Visualize architecture
    print("\n4. Visualizing model architecture...")
    visualize_model_architecture(model)

    print("\n" + "="*60)
    print("Analysis complete! All visualizations saved to /content/MMR/")
    print("Files created:")
    print("- prediction_visualization.png")
    print("- class_legend.png")
    print("- training_summary.png")
    print("- model_architecture.png")

if __name__ == "__main__":
    main()